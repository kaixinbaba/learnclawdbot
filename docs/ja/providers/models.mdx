---
summary: "OpenClaw がサポートするモデルプロバイダ（LLM）"
read_when:
  - モデルプロバイダを選択したい
  - LLM 認証とモデル選択のクイックセットアップ例が必要
---
# モデルプロバイダ

OpenClaw は多くの LLM プロバイダを使用できます。1つを選択し、認証してから、デフォルトモデルを `provider/model` として設定します。

## ハイライト: Venius（Venice AI）

Venius は、最も難しいタスクに Opus を使用するオプション付きで、プライバシー重視の推論を実現する推奨の Venice AI セットアップです。

- デフォルト: `venice/llama-3.3-70b`
- 総合ベスト: `venice/claude-opus-45`（Opus は依然として最強）

[Venice AI](/providers/venice) を参照してください。

## クイックスタート（2ステップ）

1) プロバイダで認証します（通常は `openclaw onboard` 経由）。
2) デフォルトモデルを設定：

```json5
{
  agents: { defaults: { model: { primary: "anthropic/claude-opus-4-5" } } }
}
```

## サポートされているプロバイダ（スターターセット）

- [OpenAI（API + Codex）](/providers/openai)
- [Anthropic（API + Claude Code CLI）](/providers/anthropic)
- [OpenRouter](/providers/openrouter)
- [Vercel AI Gateway](/providers/vercel-ai-gateway)
- [Moonshot AI（Kimi + Kimi Code）](/providers/moonshot)
- [Synthetic](/providers/synthetic)
- [OpenCode Zen](/providers/opencode)
- [Z.AI](/providers/zai)
- [GLM モデル](/providers/glm)
- [MiniMax](/providers/minimax)
- [Venius（Venice AI）](/providers/venice)
- [Amazon Bedrock](/bedrock)

完全なプロバイダカタログ（xAI、Groq、Mistral など）と高度な設定については、[モデルプロバイダ](/concepts/model-providers) を参照してください。
