---
summary: "Использование моделей Venice AI с фокусом на конфиденциальность в OpenClaw"
read_when:
  - Вы хотите получить приватный вывод в OpenClaw
  - Вам нужно руководство по настройке Venice AI
---
# Venice AI (выбор Venice)

**Venice** — это наша рекомендуемая настройка Venice для приватного вывода с опциональным анонимным доступом к проприетарным моделям.

Venice AI предоставляет вывод AI с фокусом на конфиденциальность с поддержкой нецензурированных моделей и доступом к основным проприетарным моделям через их анонимный прокси. Весь вывод по умолчанию приватный — без обучения на ваших данных, без логирования.

## Почему Venice в OpenClaw

- **Приватный вывод** для моделей с открытым исходным кодом (без логирования).
- **Нецензурированные модели**, когда они вам нужны.
- **Анонимный доступ** к проприетарным моделям (Opus/GPT/Gemini), когда важно качество.
- Конечные точки, совместимые с OpenAI `/v1`.

## Режимы конфиденциальности

Venice предлагает два уровня конфиденциальности — понимание этого ключ к выбору вашей модели:

| Режим | Описание | Модели |
|------|-------------|--------|
| **Приватный** | Полностью приватный. Промпты/ответы **никогда не сохраняются или не логируются**. Эфемерный. | Llama, Qwen, DeepSeek, Venice Uncensored и т.д. |
| **Анонимизированный** | Проксируется через Venice с удаленными метаданными. Базовый провайдер (OpenAI, Anthropic) видит анонимизированные запросы. | Claude, GPT, Gemini, Grok, Kimi, MiniMax |

## Функции

- **Фокус на конфиденциальность**: выбирайте между режимами "приватный" (полностью приватный) и "анонимизированный" (проксируемый)
- **Нецензурированные модели**: доступ к моделям без ограничений по контенту
- **Доступ к основным моделям**: используйте Claude, GPT-5.2, Gemini, Grok через анонимный прокси Venice
- **Совместимый API OpenAI**: стандартные конечные точки `/v1` для простой интеграции
- **Потоковая передача**: ✅ поддерживается на всех моделях
- **Вызов функций**: ✅ поддерживается на отдельных моделях (проверьте возможности модели)
- **Видение**: ✅ поддерживается на моделях с возможностью видения
- **Без жестких ограничений**: для экстремального использования может применяться честное дросселирование

## Настройка

### 1. Получите API-ключ

1. Зарегистрируйтесь на [venice.ai](https://venice.ai)
2. Перейдите в **Settings → API Keys → Create new key**
3. Скопируйте ваш API-ключ (формат: `vapi_xxxxxxxxxxxx`)

### 2. Настройте OpenClaw

**Вариант A: Переменная окружения**

```bash
export VENICE_API_KEY="vapi_xxxxxxxxxxxx"
```

**Вариант B: Интерактивная настройка (рекомендуется)**

```bash
openclaw onboard --auth-choice venice-api-key
```

Это:
1. Запросит ваш API-ключ (или использует существующий `VENICE_API_KEY`)
2. Покажет все доступные модели Venice
3. Позволит вам выбрать модель по умолчанию
4. Автоматически настроит провайдер

**Вариант C: Неинтерактивный**

```bash
openclaw onboard --non-interactive \
  --auth-choice venice-api-key \
  --venice-api-key "vapi_xxxxxxxxxxxx"
```

### 3. Проверьте настройку

```bash
openclaw chat --model venice/llama-3.3-70b "Привет, ты работаешь?"
```

## Выбор модели

После настройки OpenClaw показывает все доступные модели Venice. Выбирайте в соответствии с вашими потребностями:

- **По умолчанию (наш выбор)**: `venice/llama-3.3-70b` для приватной, сбалансированной производительности.
- **Лучшее общее качество**: `venice/claude-opus-45` для сложных задач (Opus остается самым сильным).
- **Конфиденциальность**: выбирайте "приватные" модели для полностью приватного вывода.
- **Возможности**: выбирайте "анонимизированные" модели для доступа к Claude, GPT, Gemini через прокси Venice.

Изменяйте модель по умолчанию в любое время:

```bash
openclaw models set venice/claude-opus-45
openclaw models set venice/llama-3.3-70b
```

Список всех доступных моделей:

```bash
openclaw models list | grep venice
```

## Настройка через `openclaw configure`

1. Запустите `openclaw configure`
2. Выберите **Model/auth**
3. Выберите **Venice AI**

## Какую модель мне использовать?

| Сценарий использования | Рекомендуемая модель | Почему |
|----------|-------------------|-----|
| **Общий чат** | `llama-3.3-70b` | Хорошая универсальная, полностью приватная |
| **Лучшее общее качество** | `claude-opus-45` | Opus остается самым сильным для сложных задач |
| **Конфиденциальность + качество Claude** | `claude-opus-45` | Лучшее рассуждение через анонимный прокси |
| **Программирование** | `qwen3-coder-480b-a35b-instruct` | Оптимизирован для кода, контекст 262k |
| **Задачи видения** | `qwen3-vl-235b-a22b` | Лучшая приватная модель видения |
| **Нецензурированный** | `venice-uncensored` | Без ограничений по контенту |
| **Быстрый + дешевый** | `qwen3-4b` | Легковесный, но все еще способный |
| **Сложное рассуждение** | `deepseek-v3.2` | Сильное рассуждение, приватный |

## Доступные модели (всего 25)

### Приватные модели (15) — полностью приватные, без логирования

| ID модели | Название | Контекст (токены) | Функции |
|----------|------|------------------|----------|
| `llama-3.3-70b` | Llama 3.3 70B | 131k | Общие задачи |
| `llama-3.2-3b` | Llama 3.2 3B | 131k | Быстрая, легковесная |
| `hermes-3-llama-3.1-405b` | Hermes 3 Llama 3.1 405B | 131k | Сложные задачи |
| `qwen3-235b-a22b-thinking-2507` | Qwen3 235B Thinking | 131k | Рассуждение |
| `qwen3-235b-a22b-instruct-2507` | Qwen3 235B Instruct | 131k | Общие задачи |
| `qwen3-coder-480b-a35b-instruct` | Qwen3 Coder 480B | 262k | Код |
| `qwen3-next-80b` | Qwen3 Next 80B | 262k | Общие задачи |
| `qwen3-vl-235b-a22b` | Qwen3 VL 235B | 262k | Видение |
| `qwen3-4b` | Venice Small (Qwen3 4B) | 32k | Быстрое рассуждение |
| `deepseek-v3.2` | DeepSeek V3.2 | 163k | Рассуждение |
| `venice-uncensored` | Venice Uncensored | 32k | Нецензурированный |
| `mistral-31-24b` | Venice Medium (Mistral) | 131k | Видение |
| `google-gemma-3-27b-it` | Gemma 3 27B Instruct | 202k | Видение |
| `openai-gpt-oss-120b` | OpenAI GPT OSS 120B | 131k | Общие задачи |
| `zai-org-glm-4.7` | GLM 4.7 | 202k | Рассуждение, многоязычный |

### Анонимизированные модели (10) — через прокси Venice

| ID модели | Оригинал | Контекст (токены) | Функции |
|----------|----------|------------------|----------|
| `claude-opus-45` | Claude Opus 4.5 | 202k | Рассуждение, видение |
| `claude-sonnet-45` | Claude Sonnet 4.5 | 202k | Рассуждение, видение |
| `openai-gpt-52` | GPT-5.2 | 262k | Рассуждение |
| `openai-gpt-52-codex` | GPT-5.2 Codex | 262k | Рассуждение, видение |
| `gemini-3-pro-preview` | Gemini 3 Pro | 202k | Рассуждение, видение |
| `gemini-3-flash-preview` | Gemini 3 Flash | 262k | Рассуждение, видение |
| `grok-41-fast` | Grok 4.1 Fast | 262k | Рассуждение, видение |
| `grok-code-fast-1` | Grok Code Fast 1 | 262k | Рассуждение, код |
| `kimi-k2-thinking` | Kimi K2 Thinking | 262k | Рассуждение |
| `minimax-m21` | MiniMax M2.1 | 202k | Рассуждение |

## Обнаружение моделей

OpenClaw автоматически обнаруживает модели из API Venice, когда установлен `VENICE_API_KEY`. Если API недоступен, используется статический каталог.

Конечная точка `/models` публична (аутентификация не требуется для списка), но для вывода требуется действительный API-ключ.

## Потоковая передача и поддержка инструментов

| Функция | Поддержка |
|---------|---------|
| **Потоковая передача** | ✅ Все модели |
| **Вызов функций** | ✅ Большинство моделей (проверьте `supportsFunctionCalling` в API) |
| **Видение/изображения** | ✅ Модели с отметкой "Видение" |
| **Режим JSON** | ✅ Поддерживается через `response_format` |

## Ценообразование

Venice использует систему кредитов. Проверьте [venice.ai/pricing](https://venice.ai/pricing) для текущих тарифов:

- **Приватные модели**: обычно меньшая стоимость
- **Анонимизированные модели**: похоже на прямое ценообразование API + небольшая комиссия Venice

## Сравнение: Venice vs прямой API

| Аспект | Venice (анонимизированный) | Прямой API |
|--------|---------------------|------------|
| **Конфиденциальность** | Метаданные удалены, анонимизировано | Ваш аккаунт связан |
| **Задержка** | +10-50мс (прокси) | Прямая |
| **Функции** | Большинство функций поддерживается | Полные функции |
| **Биллинг** | Кредиты Venice | Биллинг провайдера |

## Примеры использования

```bash
# Использование приватной модели по умолчанию
openclaw chat --model venice/llama-3.3-70b

# Использование Claude через Venice (анонимизировано)
openclaw chat --model venice/claude-opus-45

# Использование нецензурированной модели
openclaw chat --model venice/venice-uncensored

# Использование модели видения с изображением
openclaw chat --model venice/qwen3-vl-235b-a22b

# Использование модели для программирования
openclaw chat --model venice/qwen3-coder-480b-a35b-instruct
```

## Устранение неполадок

### API-ключ не распознан

```bash
echo $VENICE_API_KEY
openclaw models list | grep venice
```

Убедитесь, что ключ начинается с `vapi_`.

### Модель недоступна

Каталог моделей Venice обновляется динамически. Запустите `openclaw models list` для просмотра доступных моделей. Некоторые модели могут быть временно недоступны.

### Проблемы с подключением

API Venice находится по адресу `https://api.venice.ai/api/v1`. Убедитесь, что ваша сеть разрешает HTTPS-соединения.

## Пример конфигурационного файла

```json5
{
  env: { VENICE_API_KEY: "vapi_..." },
  agents: { defaults: { model: { primary: "venice/llama-3.3-70b" } } },
  models: {
    mode: "merge",
    providers: {
      venice: {
        baseUrl: "https://api.venice.ai/api/v1",
        apiKey: "${VENICE_API_KEY}",
        api: "openai-completions",
        models: [
          {
            id: "llama-3.3-70b",
            name: "Llama 3.3 70B",
            reasoning: false,
            input: ["text"],
            cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
            contextWindow: 131072,
            maxTokens: 8192
          }
        ]
      }
    }
  }
}
```

## Ссылки

- [Venice AI](https://venice.ai)
- [Документация API](https://docs.venice.ai)
- [Ценообразование](https://venice.ai/pricing)
- [Статус](https://status.venice.ai)
