---
summary: "Как OpenClaw строит контекст запроса и сообщает об использовании токенов + затратах"
read_when:
  - Объяснение использования токенов, затрат или окон контекста
  - Отладка роста контекста или поведения уплотнения
---
# Использование токенов и затраты

OpenClaw отслеживает **токены**, а не символы. Токены специфичны для модели, но большинство
моделей в стиле OpenAI в среднем составляют ~4 символа на токен для английского текста.

## Как строится системный запрос

OpenClaw собирает свой собственный системный запрос при каждом запуске. Он включает:

- Список инструментов + краткие описания
- Список навыков (только метаданные; инструкции загружаются по требованию с помощью `read`)
- Инструкции по самообновлению
- Рабочее пространство + начальные файлы (`AGENTS.md`, `SOUL.md`, `TOOLS.md`, `IDENTITY.md`, `USER.md`, `HEARTBEAT.md`, `BOOTSTRAP.md` при новом). Большие файлы обрезаются по `agents.defaults.bootstrapMaxChars` (по умолчанию: 20000).
- Время (UTC + часовой пояс пользователя)
- Теги ответа + поведение heartbeat
- Метаданные среды выполнения (хост/ОС/модель/мышление)

См. полную разбивку в [Системный запрос](/concepts/system-prompt).

## Что учитывается в окне контекста

Все, что получает модель, учитывается в лимите контекста:

- Системный запрос (все разделы, перечисленные выше)
- История разговора (сообщения пользователя + ассистента)
- Вызовы инструментов и результаты инструментов
- Вложения/транскрипты (изображения, аудио, файлы)
- Сводки уплотнения и артефакты обрезки
- Обертки провайдера или заголовки безопасности (не видны, но все равно учитываются)

Для практической разбивки (по внедренному файлу, инструментам, навыкам и размеру системного запроса) используйте `/context list` или `/context detail`. См. [Context](/concepts/context).

## Как увидеть текущее использование токенов

Используйте их в чате:

- `/status` → **карта статуса с эмодзи** с моделью сеанса, использованием контекста,
  токенами ввода/вывода последнего ответа и **оценочной стоимостью** (только API-ключ).
- `/usage off|tokens|full` → добавляет **нижний колонтитул использования на ответ** к каждому ответу.
  - Сохраняется по сеансу (хранится как `responseUsage`).
  - OAuth-аутентификация **скрывает стоимость** (только токены).
- `/usage cost` → показывает локальную сводку затрат из журналов сеансов OpenClaw.

Другие поверхности:

- **TUI/Web TUI:** `/status` + `/usage` поддерживаются.
- **CLI:** `openclaw status --usage` и `openclaw channels list` показывают
  окна квоты провайдера (не затраты на ответ).

## Оценка затрат (когда показывается)

Затраты оцениваются на основе вашей конфигурации цен модели:

```
models.providers.<provider>.models[].cost
```

Это **USD за 1 млн токенов** для `input`, `output`, `cacheRead` и
`cacheWrite`. Если цены отсутствуют, OpenClaw показывает только токены. OAuth-токены
никогда не показывают стоимость в долларах.

## TTL кеша и влияние обрезки

Кэширование запросов провайдера применяется только в окне TTL кеша. OpenClaw может
опционально выполнять **обрезку cache-ttl**: он обрезает сеанс после истечения TTL кеша,
затем сбрасывает окно кеша, чтобы последующие запросы могли повторно использовать
только что кэшированный контекст вместо повторного кэширования полной истории. Это снижает
затраты на запись в кеш, когда сеанс простаивает после истечения TTL.

Настройте это в [Конфигурация шлюза](/gateway/configuration) и см. детали
поведения в [Обрезка сеанса](/concepts/session-pruning).

Heartbeat может поддерживать кеш **теплым** во время пробелов простоя. Если TTL кеша вашей модели
составляет `1h`, установка интервала heartbeat чуть ниже этого (например, `55m`) может избежать
повторного кэширования полного запроса, снижая затраты на запись в кеш.

Для цен на API Anthropic чтение из кеша значительно дешевле, чем входные
токены, в то время как записи в кеш оплачиваются по более высокому множителю. См. цены на
кэширование запросов Anthropic для последних тарифов и множителей TTL:
https://docs.anthropic.com/docs/build-with-claude/prompt-caching

### Пример: поддерживать 1-часовой кеш теплым с heartbeat

```yaml
agents:
  defaults:
    model:
      primary: "anthropic/claude-opus-4-5"
    models:
      "anthropic/claude-opus-4-5":
        params:
          cacheControlTtl: "1h"
    heartbeat:
      every: "55m"
```

## Советы по снижению давления токенов

- Используйте `/compact` для суммирования длинных сеансов.
- Обрезайте большие выводы инструментов в ваших рабочих процессах.
- Держите описания навыков короткими (список навыков внедряется в запрос).
- Предпочитайте меньшие модели для многословной, исследовательской работы.

См. [Skills](/tools/skills) для точной формулы накладных расходов списка навыков.
