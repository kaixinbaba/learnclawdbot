---
summary: "Задачи LLM только для JSON для рабочих процессов (опциональный инструмент плагина)"
read_when:
  - Вы хотите шаг LLM только для JSON внутри рабочих процессов
  - Вам нужен валидированный по схеме вывод LLM для автоматизации
---

# LLM Task

`llm-task` — это **опциональный инструмент плагина**, который выполняет задачу LLM только для JSON и возвращает структурированный вывод (опционально валидированный по JSON Schema).

Это идеально для движков рабочих процессов, таких как Lobster: вы можете добавить один шаг LLM без написания пользовательского кода OpenClaw для каждого рабочего процесса.

## Включите плагин

1) Включите плагин:

```json
{
  "plugins": {
    "entries": {
      "llm-task": { "enabled": true }
    }
  }
}
```

2) Добавьте инструмент в список разрешений (он зарегистрирован с `optional: true`):

```json
{
  "agents": {
    "list": [
      {
        "id": "main",
        "tools": { "allow": ["llm-task"] }
      }
    ]
  }
}
```

## Конфигурация (необязательно)

```json
{
  "plugins": {
    "entries": {
      "llm-task": {
        "enabled": true,
        "config": {
          "defaultProvider": "openai-codex",
          "defaultModel": "gpt-5.2",
          "defaultAuthProfileId": "main",
          "allowedModels": ["openai-codex/gpt-5.2"],
          "maxTokens": 800,
          "timeoutMs": 30000
        }
      }
    }
  }
}
```

`allowedModels` — это список разрешений строк `provider/model`. Если установлен, любой запрос вне списка отклоняется.

## Параметры инструмента

- `prompt` (строка, обязательно)
- `input` (любой, необязательно)
- `schema` (объект, необязательная JSON Schema)
- `provider` (строка, необязательно)
- `model` (строка, необязательно)
- `authProfileId` (строка, необязательно)
- `temperature` (число, необязательно)
- `maxTokens` (число, необязательно)
- `timeoutMs` (число, необязательно)

## Вывод

Возвращает `details.json`, содержащий разобранный JSON (и валидирует по `schema`, когда предоставлено).

## Пример: Шаг рабочего процесса Lobster

```lobster
openclaw.invoke --tool llm-task --action json --args-json '{
  "prompt": "Given the input email, return intent and draft.",
  "input": {
    "subject": "Hello",
    "body": "Can you help?"
  },
  "schema": {
    "type": "object",
    "properties": {
      "intent": { "type": "string" },
      "draft": { "type": "string" }
    },
    "required": ["intent", "draft"],
    "additionalProperties": false
  }
}'
```

## Примечания безопасности

- Инструмент **только для JSON** и инструктирует модель выводить только JSON (без блоков кода, без комментариев).
- Инструменты не предоставляются модели для этого запуска.
- Рассматривайте вывод как недоверенный, если вы не валидируете с помощью `schema`.
- Поместите одобрения перед любым шагом с побочными эффектами (отправка, публикация, exec).
